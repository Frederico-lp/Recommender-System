{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1063, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# dataset is accessible at https://s3.amazonaws.com/amazon-reviews-pds/tsv/index.txt (https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Books_v1_02.tsv.gz)\n",
    "df = pd.read_csv('amazon_reviews_us_Digital_Software_v1_00.tsv', sep='\\t', dtype={'star_rating': float})\n",
    "\n",
    "df.columns = ['marketplace', 'customer_id', 'review_id', 'product_id', 'product_parent', 'product_title', 'product_category', 'star_rating',\n",
    "              'helpful_votes', 'total_votes', 'vine', 'verified_purchase', 'review_headline', 'review_body', 'review_date']\n",
    "\n",
    "df.drop(['marketplace', 'product_parent', 'product_title', 'product_category', 'helpful_votes', 'total_votes', 'vine', 'verified_purchase',\n",
    "         'review_headline'],\n",
    "        axis='columns', inplace=True)\n",
    "\n",
    "# Using just a subset of the data (the one with more common id in order for there to be more correlation)\n",
    "\n",
    "customer_count = df['customer_id'].value_counts()\n",
    "customers_with_multiple_reviews = customer_count[customer_count > 3].index\n",
    "df = df[df['customer_id'].isin(customers_with_multiple_reviews)]\n",
    "\n",
    "product_count = df['product_id'].value_counts()\n",
    "products_with_multiple_reviews = product_count[product_count > 3].index\n",
    "df = df[df['product_id'].isin(products_with_multiple_reviews)]\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137, 6)\n"
     ]
    }
   ],
   "source": [
    "def apply_pivot(df, fillby=None):\n",
    "    pivot_table = df.pivot_table(index='customer_id', columns='product_id', values='star_rating')\n",
    "    if fillby is not None:\n",
    "        pivot_table = pivot_table.fillna(fillby)\n",
    "    return pivot_table\n",
    "\n",
    "# Train-test split (training on older data to predict more recent data)\n",
    "df = df.sort_values(by='review_date')\n",
    "\n",
    "split_index = int(0.7 * len(df))\n",
    "\n",
    "train = df[:split_index]\n",
    "test = df[split_index:]\n",
    "\n",
    "test = test[test.customer_id.isin(train.customer_id)] # to guarantee known customer ids in test\n",
    "test = test[test.product_id.isin(train.product_id)] # to guarantee known product ids in test\n",
    "\n",
    "df_train_pivot = apply_pivot(df = train, fillby = 0)\n",
    "df_test_pivot = apply_pivot(df = test, fillby = 0)\n",
    "\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummies to help to know wether a product has been rated or not\n",
    "# Train\n",
    "dummy_train = train.copy()\n",
    "\n",
    "# Exclude products already rated by the user\n",
    "# Obtain a table with 0 when products have been rated and 1 when they haven't\n",
    "dummy_train['star_rating'] = dummy_train['star_rating'].apply(lambda x: 0 if x >= 1 else 1) \n",
    "dummy_train = apply_pivot(df = dummy_train, fillby = 1)\n",
    "\n",
    "# Exclude products not rated by the user\n",
    "# Obtain a table with 1 when products have been rated and 0 when they haven't\n",
    "dummy_test = test.copy()\n",
    "dummy_test['star_rating'] = dummy_test['star_rating'].apply(lambda x: 1 if x >= 1 else 0)\n",
    "dummy_test = apply_pivot(df = dummy_test, fillby = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and subtract it from ratings for ajusted cosine similarity\n",
    "train_pivot = apply_pivot(df=train)\n",
    "mean = train_pivot.mean(axis=1, skipna=True)\n",
    "\n",
    "df_train_subtracted = train_pivot.sub(mean, axis=0)\n",
    "\n",
    "# Set ratings to 0 where a user hasn't given any rating\n",
    "df_train_subtracted.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the User Similarity Matrix\n",
    "user_correlation = 1 - pairwise_distances(df_train_subtracted, metric='cosine')\n",
    "user_correlation[np.isnan(user_correlation)] = 0\n",
    "\n",
    "user_correlation_df = pd.DataFrame(user_correlation, index=df_train_subtracted.index, columns=df_train_subtracted.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating predicted by the user is weighted sum of correlation with the product rating \n",
    "user_predicted_ratings = np.dot(user_correlation, df_train_pivot)\n",
    "\n",
    "# Products not rated by user \n",
    "user_final_rating = np.multiply(user_predicted_ratings,dummy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fisica1\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\preprocessing\\_data.py:473: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\Fisica1\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\preprocessing\\_data.py:474: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n"
     ]
    }
   ],
   "source": [
    "#Filter user correlation only for customer_id which is in test\n",
    "user_correlation_test_df = user_correlation_df[user_correlation_df.index.isin(test.customer_id)]\n",
    "user_correlation_test_df = user_correlation_test_df[list(set(test.customer_id))]\n",
    "\n",
    "#Get test user predicted rating\n",
    "test_user_predicted_ratings = np.dot(user_correlation_test_df, df_test_pivot)\n",
    "test_user_predicted_ratings = np.multiply(test_user_predicted_ratings,dummy_test)\n",
    "test_user_predicted_ratings = test_user_predicted_ratings[test_user_predicted_ratings > 0]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(1, 5))\n",
    "scaler.fit(test_user_predicted_ratings)\n",
    "test_user_predicted_ratings = scaler.transform(test_user_predicted_ratings)\n",
    "\n",
    "predicted_ratings_df = pd.DataFrame(test_user_predicted_ratings, index=df_test_pivot.index, columns=df_test_pivot.columns)\n",
    "\n",
    "predicted_ratings_df = predicted_ratings_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:2.856406471812678\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE\n",
    "total_non_nan = np.count_nonzero(~np.isnan(test_user_predicted_ratings))\n",
    "rmse = (np.sum(np.sum((df_test_pivot - test_user_predicted_ratings)**2))/total_non_nan)**0.5\n",
    "print(\"RMSE:\" + str(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision at 5: 0.041509433962264156\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision at k\n",
    "\n",
    "def precision_at_k(actual, predicted, k):\n",
    "    precision_values = []\n",
    "    for user in actual.index:\n",
    "        actual_items = actual.loc[user]  # Actual user preferences\n",
    "        rated_items = actual_items[actual_items > 0].index  # Items rated by the user\n",
    "        predicted_items = predicted.loc[user].nlargest(k).index # Top K recommended items\n",
    "        num_relevant = len(set(rated_items) & set(predicted_items))  # Number of relevant items\n",
    "        precision = num_relevant / k  # Precision at K\n",
    "        precision_values.append(precision)\n",
    "    average_precision = np.mean(precision_values)\n",
    "    return average_precision\n",
    "\n",
    "k = 5\n",
    "\n",
    "precision = precision_at_k(df_test_pivot, predicted_ratings_df, k)\n",
    "print(\"Precision at \"+ str(k) + \": \" + str(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(user_final_rating,open('./user_final_rating.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "ef5e170586bc6a0be4aa28ebe27a5d2994966adc9d903ffa425305698ffcf453"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
