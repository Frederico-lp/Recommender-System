{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        customer_id       review_id  product_id  \\\n",
      "2793       14297784   R1RDB9C91XPF0  B000JLNHO6   \n",
      "15096      19802240  R2MTDG51GV59MS  B000YMNI2Q   \n",
      "99226      39503814  R2LRAB7GM83D56  B000YMNI2Q   \n",
      "96894      14346072  R1YKWHT9ADKWWN  B000YMNI76   \n",
      "101155     52744918  R20V03BFCC4Q76  B00194IWVK   \n",
      "...             ...             ...         ...   \n",
      "2643       34362164  R1XY7EM5DW79UE  B01019BOEA   \n",
      "2268       44425668  R2CNQKNOLUH8ED  B01019BOEA   \n",
      "3112       48216980  R3O4WQWL638OO0  B010909498   \n",
      "4672       24267541  R172GVQEMEB3JA  B010BTET5Q   \n",
      "1601        2917773  R313E51X4NISQS  B012Y7R126   \n",
      "\n",
      "                                     product_title  product_category  \\\n",
      "2793                        TurboTax Business 2007  Digital_Software   \n",
      "15096                          TurboTax Basic 2007  Digital_Software   \n",
      "99226                          TurboTax Basic 2007  Digital_Software   \n",
      "96894                 TurboTax Deluxe Federal 2007  Digital_Software   \n",
      "101155  Better Homes and Gardens Home Designer 8.0  Digital_Software   \n",
      "...                                            ...               ...   \n",
      "2643           Microsoft Windows 10 Pro | Download  Digital_Software   \n",
      "2268           Microsoft Windows 10 Pro | Download  Digital_Software   \n",
      "3112              WPS Office - Suppress [Download]  Digital_Software   \n",
      "4672       chess - tactics and strategy [Download]  Digital_Software   \n",
      "1601       Professor Teaches Windows 10 [Download]  Digital_Software   \n",
      "\n",
      "        star_rating                                        review_body  \\\n",
      "2793            5.0  TurboTax Business is very easy to download and...   \n",
      "15096           1.0  do not buy this pay more for deluxe,very dissa...   \n",
      "99226           5.0  Turbo tax has never let me down. This download...   \n",
      "96894           5.0  [Edited 3-12-2012] OOps- wrong product, posted...   \n",
      "101155          2.0  There is a steep learning curve to this one.  ...   \n",
      "...             ...                                                ...   \n",
      "2643            5.0  Got my upgrade notice and immediately download...   \n",
      "2268            1.0  spyware, tracks everything i do, takes all my ...   \n",
      "3112            5.0  Easy to use and truly compatible at a fraction...   \n",
      "4672            5.0                                   Really nice app!   \n",
      "1601            5.0  This is good interactive training. I'm half wa...   \n",
      "\n",
      "       review_date  \n",
      "2793    2015-07-28  \n",
      "15096   2015-04-05  \n",
      "99226   2011-06-14  \n",
      "96894   2012-03-12  \n",
      "101155  2010-04-05  \n",
      "...            ...  \n",
      "2643    2015-07-30  \n",
      "2268    2015-08-04  \n",
      "3112    2015-07-23  \n",
      "4672    2015-07-04  \n",
      "1601    2015-08-11  \n",
      "\n",
      "[13648 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# dataset is accessible at https://s3.amazonaws.com/amazon-reviews-pds/tsv/index.txt (https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Books_v1_02.tsv.gz)\n",
    "df = pd.read_csv('amazon_reviews_us_Digital_Software_v1_00.tsv', sep='\\t', dtype={'star_rating': float})\n",
    "\n",
    "df.columns = ['marketplace', 'customer_id', 'review_id', 'product_id', 'product_parent', 'product_title', 'product_category', 'star_rating',\n",
    "              'helpful_votes', 'total_votes', 'vine', 'verified_purchase', 'review_headline', 'review_body', 'review_date']\n",
    "\n",
    "df.drop(['marketplace', 'product_parent', 'helpful_votes', 'total_votes', 'vine', 'verified_purchase', 'review_headline'],\n",
    "        axis='columns', inplace=True)\n",
    "\n",
    "# Using just a subset of the data (the one with more common id in order for there to be more correlation)\n",
    "\n",
    "review_counts = df['customer_id'].value_counts()\n",
    "customers_with_multiple_reviews = review_counts[review_counts > 1].index\n",
    "df = df[df['customer_id'].isin(customers_with_multiple_reviews)]\n",
    "\n",
    "df = df.sort_values(by=['product_id', 'customer_id'])\n",
    "\n",
    "# df = df[:10000]\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1901, 8)\n"
     ]
    }
   ],
   "source": [
    "def apply_pivot(df, fillby=None):\n",
    "    pivot_table = df.pivot_table(index='customer_id', columns='product_id', values='star_rating')\n",
    "    if fillby is not None:\n",
    "        pivot_table = pivot_table.fillna(fillby)\n",
    "    return pivot_table\n",
    "\n",
    "# Train-test split (training on older data to predict more recent data)\n",
    "df = df.sort_values(by='review_date')\n",
    "\n",
    "train_ratio = 0.7\n",
    "split_index = int(train_ratio * len(df))\n",
    "\n",
    "train = df[:split_index]\n",
    "test = df[split_index:]\n",
    "\n",
    "test = test[test.customer_id.isin(train.customer_id)] # to guarantee known customer ids in test\n",
    "\n",
    "df_train_pivot = apply_pivot(df = train, fillby = 0)\n",
    "df_test_pivot = apply_pivot(df = test, fillby = 0)\n",
    "\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummies to help to know wether a product has been rated or not\n",
    "# Train\n",
    "dummy_train = train.copy()\n",
    "\n",
    "# Exclude products already rated by the user\n",
    "# Obtain a table with 0 when products have been rated and 1 when they haven't\n",
    "dummy_train['star_rating'] = dummy_train['star_rating'].apply(lambda x: 0 if x >= 1 else 1) \n",
    "dummy_train = apply_pivot(df = dummy_train, fillby = 1)\n",
    "\n",
    "# Exclude products not rated by the user\n",
    "# Obtain a table with 1 when products have been rated and 0 when they haven't\n",
    "dummy_test = test.copy()\n",
    "dummy_test['star_rating'] = dummy_test['star_rating'].apply(lambda x: 1 if x >= 1 else 0)\n",
    "dummy_test = apply_pivot(df = dummy_test, fillby = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and subtract it from ratings for ajusted cosine similarity\n",
    "train_pivot = apply_pivot(df=train)\n",
    "mean = train_pivot.mean(axis=1, skipna=True)\n",
    "\n",
    "df_train_subtracted = train_pivot.sub(mean, axis=0)\n",
    "\n",
    "# Set ratings to 0 where a user hasn't given any rating\n",
    "df_train_subtracted.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the User Similarity Matrix\n",
    "user_correlation = 1 - pairwise_distances(df_train_subtracted, metric='cosine')\n",
    "user_correlation[np.isnan(user_correlation)] = 0\n",
    "\n",
    "user_correlation_df = pd.DataFrame(user_correlation, index=df_train_subtracted.index, columns=df_train_subtracted.index)\n",
    "\n",
    "#print(user_correlation_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating predicted by the user is weighted sum of correlation with the product rating \n",
    "user_predicted_ratings = np.dot(user_correlation, df_train_pivot)\n",
    "\n",
    "# Products not rated by user \n",
    "user_final_rating = np.multiply(user_predicted_ratings,dummy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fisica1\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\preprocessing\\_data.py:473: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\Fisica1\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\preprocessing\\_data.py:474: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n"
     ]
    }
   ],
   "source": [
    "#Filter user correlation only for user which is in test, test is subset/equal of train in terms of userId\n",
    "\n",
    "user_correlation_test_df = user_correlation_df[user_correlation_df.index.isin(test.customer_id)]\n",
    "user_correlation_test_df = user_correlation_test_df[list(set(test.customer_id))]\n",
    "\n",
    "#Get test user predicted rating\n",
    "test_user_predicted_ratings = np.dot(user_correlation_test_df, df_test_pivot)\n",
    "test_user_predicted_ratings = np.multiply(test_user_predicted_ratings,dummy_test)\n",
    "test_user_predicted_ratings = test_user_predicted_ratings[test_user_predicted_ratings > 0]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(1, 5))\n",
    "scaler.fit(test_user_predicted_ratings)\n",
    "test_user_predicted_ratings = scaler.transform(test_user_predicted_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4548849040095906\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE\n",
    "\n",
    "total_non_nan = np.count_nonzero(~np.isnan(test_user_predicted_ratings))\n",
    "rmse = (np.sum(np.sum((df_test_pivot - test_user_predicted_ratings)**2))/total_non_nan)**0.5\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision at 1000 : 0.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision at k\n",
    "\n",
    "def precision_at_k(actual, predicted, k):\n",
    "    precision_values = []\n",
    "    for user in actual.index:\n",
    "        actual_items = actual.loc[user]  # Actual user preferences\n",
    "        predicted_items = predicted.loc[user].nlargest(k).index  # Top K recommended items\n",
    "        num_relevant = len(set(actual_items) & set(predicted_items))  # Number of relevant items\n",
    "        precision = num_relevant / k  # Precision at K\n",
    "        precision_values.append(precision)\n",
    "    average_precision = np.mean(precision_values)\n",
    "    return average_precision\n",
    "\n",
    "k = 10\n",
    "\n",
    "precision = precision_at_k(df_test_pivot, user_final_rating, 5)\n",
    "print(\"Precision at\", k, \":\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(user_final_rating,open('./user_final_rating.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "ef5e170586bc6a0be4aa28ebe27a5d2994966adc9d903ffa425305698ffcf453"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
