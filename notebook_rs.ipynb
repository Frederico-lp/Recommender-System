{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         4.0\n",
      "1         3.0\n",
      "2         1.0\n",
      "3         5.0\n",
      "4         4.0\n",
      "         ... \n",
      "101831    2.0\n",
      "101832    4.0\n",
      "101833    2.0\n",
      "101834    3.0\n",
      "101835    1.0\n",
      "Name: star_rating, Length: 101836, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# dataset is accessible at https://s3.amazonaws.com/amazon-reviews-pds/tsv/index.txt (https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Books_v1_02.tsv.gz)\n",
    "df = pd.read_csv('amazon_reviews_us_Digital_Software_v1_00.tsv', sep='\\t', dtype={'star_rating': float})\n",
    "\n",
    "df.columns = ['marketplace', 'customer_id', 'review_id', 'product_id', 'product_parent', 'product_title', 'product_category', 'star_rating',\n",
    "              'helpful_votes', 'total_votes', 'vine', 'verified_purchase', 'review_headline', 'review_body', 'review_date']\n",
    "\n",
    "print(df['star_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_id    B000JLNHO6    B000YMNI2Q    B000YMNI76    B000YMR5X4  \\\n",
      "count       67154.000000  67154.000000  67154.000000  67154.000000   \n",
      "mean            0.999985      0.999955      0.999985      0.999926   \n",
      "std             0.003859      0.006684      0.003859      0.008629   \n",
      "min             0.000000      0.000000      0.000000      0.000000   \n",
      "25%             1.000000      1.000000      1.000000      1.000000   \n",
      "50%             1.000000      1.000000      1.000000      1.000000   \n",
      "75%             1.000000      1.000000      1.000000      1.000000   \n",
      "max             1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "product_id    B000YMR61A    B000YMR6AG    B000YMRM8W    B00194DS1Y  \\\n",
      "count       67154.000000  67154.000000  67154.000000  67154.000000   \n",
      "mean            0.999687      0.999970      0.999970      0.999985   \n",
      "std             0.017681      0.005457      0.005457      0.003859   \n",
      "min             0.000000      0.000000      0.000000      0.000000   \n",
      "25%             1.000000      1.000000      1.000000      1.000000   \n",
      "50%             1.000000      1.000000      1.000000      1.000000   \n",
      "75%             1.000000      1.000000      1.000000      1.000000   \n",
      "max             1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "product_id    B00194GSSY    B00194IWVK  ...    B012P6LBVI    B012P6LVXQ  \\\n",
      "count       67154.000000  67154.000000  ...  67154.000000  67154.000000   \n",
      "mean            0.999970      0.999955  ...      0.999985      0.999985   \n",
      "std             0.005457      0.006684  ...      0.003859      0.003859   \n",
      "min             0.000000      0.000000  ...      0.000000      0.000000   \n",
      "25%             1.000000      1.000000  ...      1.000000      1.000000   \n",
      "50%             1.000000      1.000000  ...      1.000000      1.000000   \n",
      "75%             1.000000      1.000000  ...      1.000000      1.000000   \n",
      "max             1.000000      1.000000  ...      1.000000      1.000000   \n",
      "\n",
      "product_id    B012P6MKDQ    B012P6PS8U    B012VQNGD8    B012X77XPM  \\\n",
      "count       67154.000000  67154.000000  67154.000000  67154.000000   \n",
      "mean            0.999985      0.999985      0.999985      0.999970   \n",
      "std             0.003859      0.003859      0.003859      0.005457   \n",
      "min             0.000000      0.000000      0.000000      0.000000   \n",
      "25%             1.000000      1.000000      1.000000      1.000000   \n",
      "50%             1.000000      1.000000      1.000000      1.000000   \n",
      "75%             1.000000      1.000000      1.000000      1.000000   \n",
      "max             1.000000      1.000000      1.000000      1.000000   \n",
      "\n",
      "product_id    B012Y7R126    B01349UVFW    B013YHE73G    BT00IU6O8K  \n",
      "count       67154.000000  67154.000000  67154.000000  67154.000000  \n",
      "mean            0.999970      0.999970      0.999985      0.999955  \n",
      "std             0.005457      0.005457      0.003859      0.006684  \n",
      "min             0.000000      0.000000      0.000000      0.000000  \n",
      "25%             1.000000      1.000000      1.000000      1.000000  \n",
      "50%             1.000000      1.000000      1.000000      1.000000  \n",
      "75%             1.000000      1.000000      1.000000      1.000000  \n",
      "max             1.000000      1.000000      1.000000      1.000000  \n",
      "\n",
      "[8 rows x 2650 columns]\n"
     ]
    }
   ],
   "source": [
    "def apply_pivot(df,fillby = None):\n",
    "    if fillby is not None:\n",
    "        return df.pivot_table(index='customer_id', columns='product_id',values='star_rating').fillna(fillby)\n",
    "    return df.pivot_table(index='customer_id', columns='product_id', values='star_rating')\n",
    "\n",
    "# Train-test split (possivelmente deviamos por no training os mais antigos para prever o futuro)\n",
    "train, test = train_test_split(df, test_size=0.30, random_state=42)\n",
    "test = test[test.customer_id.isin(train.customer_id)]\n",
    "\n",
    "# Check for duplicate customer_if - product_id pairs\n",
    "#print(train.duplicated(['customer_id', 'product_id']).sum())\n",
    "\n",
    "# Eliminate duplicates\n",
    "train = train.drop_duplicates(['customer_id', 'product_id'])\n",
    "\n",
    "df_train_pivot = apply_pivot(df = train, fillby = 0)\n",
    "df_test_pivot = apply_pivot(df = test, fillby = 0)\n",
    "\n",
    "# Para ver se existem valores não NaN\n",
    "#print(df_train_pivot.count())\n",
    "#print(df_train_pivot.isna().sum())\n",
    "#print(df_train_pivot)\n",
    "\n",
    "# Train\n",
    "dummy_train = train.copy()\n",
    "\n",
    "# Replace non-numeric values in 'star_rating' column with NaN (possivelmente podia-se substituir pela média ou assim e não por 0)\n",
    "dummy_train['star_rating'] = pd.to_numeric(dummy_train['star_rating'], errors='coerce')\n",
    "\n",
    "# Exclude products already rated by the user\n",
    "dummy_train['star_rating'] = dummy_train['star_rating'].apply(lambda x: 0 if x>=1 else 1)\n",
    "dummy_train = apply_pivot(df = dummy_train, fillby = 1)\n",
    "\n",
    "# Test\n",
    "dummy_test = test.copy()\n",
    "dummy_test['star_rating'] = dummy_test['star_rating'].apply(lambda x: 1 if x>=1 else 0)\n",
    "dummy_test = apply_pivot(df = dummy_test, fillby = 0)\n",
    "\n",
    "print(dummy_train.describe())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "ef5e170586bc6a0be4aa28ebe27a5d2994966adc9d903ffa425305698ffcf453"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
